<pre class='metadata'>
Title: Technical Image Metadata
Shortname: tim
Level: 1
Status: fido/ED
Group: Inclusio Project
Repository: fizzstudio/technical-image-metadata
URL: https://fizzstudio.github.io/technical-image-metadata/
Editor: Doug Schepers, Fizz Studio http://fizz.studio, doug@fizz.studio
Abstract: A specifiction for expressing technical image metadata, with an emphasis on accessibility of data visualizations.
Favicon: ./favicon.svg
Complain About: accidental-2119 yes, missing-example-ids yes
Markup Shorthands: markdown yes, css no
</pre>

Introduction {#intro}
=====================

This specification defines a structured metadata schema for image documents to express information, data, and behaviors related to the visual image, with a particular emphasis on accessibility. The metadata includes raw data, provenance information, and predefined behaviors for assistive technology techniques, such as haptics, sonification, tactiles, high contrast, voicing, braille, and more.

The metadata is aimed primarily at data visualizations such as charts, graphs, diagrams and other information graphics, but can also be used for related purposes in any image.

It is intended for use with a structured graphics markup such as Scalable Vector Graphics (SVG), but could be embedded in and applied to any image format, including raster images and 3D-printed objects and scenes.

## Motivation ## {#motivation}

This specification was written to help unify and standardize accessible graphics, and to enable systemic experimentation with assistive technology techniques. By defining the way techniques such as haptics, sonification, and tactiles are expressed in a declarative way, the parameters can be explored and tested with users to ensure ease of consistent authoring and interoperable behavior across different assistive technology readers and devices.

By standardizing the accessibility features of a document, we enable users (such as people with disabilities, or teachers or caregivers of people with disabilities) to easily find content that matches their needs, or to find content they want to adapt or have adapted for their needs. This provides a meaningful path towards the curation, creation, and adaptation of accessible content, which is one of the primary gaps in accessibility today, particularly in education.

Of particular note is support for hybrid physical-digital documents, such as printed or embossed images that are overlaid on a touch screen where the digital equivalent is mirrored, so that a tactile experience can be enhanced with haptics or voicing. Similarly, a 3D-printed object could be used with a camera scanner to associate sections of the object with specific metadata.

This specification uses familiar technologies such as JSON [[JSON-Schema]] and CSS Selectors [[Selectors-4]], for ease of implementation and authoring.

<!--
<pre class='railroad'>
T: /*
ZeroOrMore:
  N: anything but * followed by /
T: */
</pre>
-->

Goals {#goals} 
=====================

## Interoperability ## {#interoperability}

This specification should be complete and definitive with the state of the art, to prevent the need for additional or competing specifications that would decrease interoperability.

## Personalization ## {#personalization}

This assistive technology must enable the user to select which of the available accomodations are enabled at any time, and at which available effect level. This must be able to set as a default in the user agent, and must be overrideable by the user to meet their specific need at any time.

Any given end-user might have multiple disabilities, with varying degrees of effect at any given time; any given document might have multiple accomodations enabled and encoded in it; any given user agent might suport multiple assistive technologies; any given environment might have different affordances and constraints.

<div id='xmp_low_vision_high_contrast' class='example'>
A low vision user might wish to enable very high contrast in a bright environment or when they are tired, and lower contrast when they are in a more moderately lighted environment and well-rested.
</div>

<div id='xmp_blind_env_conditions' class='example'>
A blind user might wish to enable haptics and braille output when they are in a quiet zone or noisy environment, and sonification and spoken output when they are in a private, quiet environment.
</div>

## Security ## {#security}

The distribution of interactive content presents a conflict between innovative capabilities and user security. In the web platform, most advanced interactivity can only be achieved through JavaScript, but allowing JavaScript in a file opens the user's system up to possible security holes.

This is often unexpected and overlooked in images, but SVG (unlike most image formats) allows the inclusion of arbitrary JavaScript, including remote references to external JavaScript files. For this reason, many software applications (such as conent management systems or email servers) might strip out the script element, disabling the interactivity of the content.

By defining a set of declarative syntaxes for different assistive technologies, including parameters and conditional execution triggers, this specification enables the user agent to provide the interactivity defined by the author, without compromising security. This specification refers to such declarative capabilities as "behaviors".

## Privacy ## {#privacy}

By enabling security through declarative behaviors, this specification ensures the privacy of the user from third parties. Note that data collection might still be performed through some primary user agents and content providers, but this should be done only with the user's consent.

## Portability ## {#portability}

Data visualizations can often lose their association with their context, including the article they were published in or the data they represent. This specification must define a way to include the raw data and the provenance in the image file, so the context can be preserved as the document is shared through various means.

## Reuseability ## {#reuseability}

This specification should include a versatile way to include the raw data, or a link to it, in the data visualization file that represents it. By doing this, other authors are empowered to extract the data, creaste different representations, mix the data with other datasets, subset the data, verify the accuracy of the representation, and otherwise practice good data science.

In addition, a visual image can be enhanced with different metadata to serve a different purpose, such as providing a different set of descriptions for an audience at different reading levels, or translating the document into another language.

## Familiarity ## {#familiarity}

Document technologies are most useful when the syntax and model is familiar and unambiguous. This allows for ease of implementation, increased interoperability, and ease of authoring. This specification should use common technologies like JSON and CSS as its underpinnings.

## Flexibility ## {#flexibility}

This specification should be able to define the full range of expression for any assistive technology technique. The current version should detail parameters for haptics, sonification, tactiles, high contrast, voicing, and braille, and should be extensible to accomodate other techniques in the future.

At the same time, this specification should establish defaults and baselines based on best practices, wherever possible, to encourage good authoring and normalize user experience.

## Searching and categorization ## {#searching_categorization}

This specification must define easy ways to enable the distribution and discovery of content based on user needs and accomodation provided in the document. One way to do this is to provide a standardized way to express keyword tags, ratings, and capabilities within the document itself.

## Provenance expression ## {#provenance_expression}

Where, when, and by whom an image was created is often very important information, not least because it can enable the user to find more cotent by any given author, or to verify the quality of the source. It can also provide a "provenance chain", where content that has been adapted to specific needs beyond its original publisher can be share, wile also providing credit to the original author or publisher.

## Non-goals ## {#nongoals}
### Formal semantics and namespaces ### {#formal_semantics_namespaces}

While namespaces allow a flexible extensibility and modularity, they also hamper and complicate authoring and reading. This document will avoid the use of namespaces, and related technologies such as JSON-LD. Future supplements to this specification might define a JSON-LD schema, if demand exists for it.

### Generic styling ### {#generic_styling}

While this specification does includes some accessibility-specific extensions of CSS, such as a finer control of color contrast settings, it must not define or be used to supercede CSS.

Schema {#schema} 
=====================

<div class='note'>
Note that the examples below are notional, and intended for illustrative purposes. They are not a formal definition. The final definitions will likely be expressed in [[JSON-Schema]], and will include data types for each member.
</div>

This vocabulary is defined in terms of "blocks", or objects identified by a key with a defined set of optional sub-keys. This includes the <code>data</code>, <code>provenance</code>, <code>tags</code>, and <code>behaviors</code> blocks.

```json
{
  "data": {
  },
  "provenance": {
  },
  "tags": {
  },
  "behaviors": {
  },
  "href": {
  }
}
```

## External files ## {#external_files}

A metadata object can be inline in the file, or referenced as an external file, in whole or in part. There are several reasons to support external metadata files. Two major use cases include size restrictions and shared resources.

Size restrictions: While including the raw data in the image is a best practice, sometimes a dataset is simply too large to pragmatically include inline. In this case, referencing a raw data file is the best practical approach.

Shared resources: An author might wish to share a common metadata file or set of files for a set of image documents. This allows the metadata files to be updated independently, reduces duplication and file size, enables cacheing in the user agent, and allows for a modular approach with well-tested rules.

The <code>href</code> key defines an object that refers to an external file. This external file must be loaded by the user agent, and applied following the same processing rules as an inline metadata file, with the exception of the <code>data</code> block.

If an external metadata file contains rules that duplicate or conflict with rules defined in the inline metadata, the inline metadata takes precendence. This allows for customization of specific images while relying on generic common rules.

An <code>href</code> key may be included at any level of the metadata, with the relevant key string as the attribute key and a valid URL string as the value for that attribute.

<xmp highlight='json'>
{
  "href": {
    "data": "https://path.to.data",
    "provenance": "https://path.to.provenance",
    "tags": "https://path.to.tags",
    "behaviors": "https://path.to.behaviors"
  }
}
</xmp>

An additional default key is defined for referring to a single external metadata file that contains all the metadata blocks. This external file must be loaded by the user agent, and applied following the same processing rules as an inline metadata file.

<xmp highlight='json'>
{
  "href": {
    "default": "https://path.to.metadata"
  }
}
</xmp>


## Data ## {#data}

Data refers to the raw data which the image represents.

There are two ways to link the data to the image file: inline; and external reference. These methods can be used together in some ways, defined below.

A <code>data</code> block is an object with the key <code>data</code>.

<xmp highlight='json'>
{
  "data": {
    "title": {
    },
    "subtitle": {
    },
    "source": {
    },
    "axes": {
    },
    "series": {
    },
    "href": {
    }
  }
}
</xmp>
  

The individual entries of the <code>data</code> block are defined in [Inline data].

### The <code>href</code> key in a <code>data</code> block ### {#href_data_block}

The <code>href</code> key defines an object that refers to an external data file. The content model and processing of the <code>href</code> key are different in the <code>data</code> block than in other metadata blocks.

This external file can be used to link data to graphical elements, as defined in [Inline data].

### Inline data ### {#inline_data}

If a dataset is fairly small, it is best to include it in the image file directly.

#### Linking data and representational elements #### {#linking_data}

<div class="note">
<b>Note:<b> We might define specific formats for chart data, but this could be complex and time consuming. We might wish to standardize on Vega/Vega-Lite, or another common way to represent raw data.
</div>


### External reference ### {#external_re}

<div class="note">
<b>Note:<b> It might seem unintuitive to refer to data as metadata, but in the context of a graphics image file, the "data" of the file is the graphical elements that compose the file, while the raw data that is being represented is the metadata.
</div>


## Provenance ## {#provenance}

Provenance describes where a document came from. This includes entries such as authors, organizations, data and time created or modified, where it was first published, the title of the paper or article it supplemented, or the original work on which it was based.

A <code>provenance</code> block is an object with the key <code>provenance</code>.

<xmp highlight='json'>
{
  "provenance": {
    "notes": {
      "item 1",
      "item 2"
    }
  }
}
</xmp>

### Notes ### {#notes}

The notes key defines an array where any details not covered by specific keys can be identified. This might include the name of the organization or individuals who sponsored the work, a dedications to a meaningful person in the author's life, and so on.

Each item should be a quoted string separated by a comma.

<xmp highlight='json'>
{
  "provenance": {
    "notes": [
      "item 1",
      "item 2"
    ]
  }
}  
</xmp>

## Tags ## {#tags}

Tags are a way to categorize the file, either by the the content, by the capabilities, or by a rating system, or some combination thereof.

Tags are used to aid in the filtering and searching for content.

### Keywords ### {#keywords}

The keywords key denotes an array of user-defined strings. Examples of keywords include labels from a folksonomy, terms defined in a formal document, steps in a workflow process, short descriptions of items depicted in the image, or any other strings.

<xmp highlight='json'>
{
  "tags": {
    "keywords": [
      "barchart",
      "design_phase",
      "unreviewed",
      "needs_braille"
    ]
  }
}
</xmp>

### Capabilities and ratings ### {#capabilities_ratings}

<div class="note">
<b>Note:<b> This is a rough notion of how we might define
</div>

The capabilities key denotes an object that includes which accomodations have been defined in the image document, and some system of rating that scores the effectiveness of that accomodation.

Each capability defines an array of capability instances, each of which consists of a least a condition of applicability, and a rating.

<xmp highlight='json'>
{
  "capabilities": {
    "haptic": [
      {
        "condition": "(insert haptic device capability here)",
        "ratings": [
          {
            "user": "Devin C.",
            "username": "dev",
            "rating": "7",
            "comments": "Works well on device X, but not device Y"
          }
        ]
      }
    ],
    "tactile": [
      {
        "condition": "@media print and (min-resolution: 300dpi)",
        "ratings": []
      },
      {
        "condition": "@media (min-resolution: 100dpi)",
        "ratings": []
      }    
    ]
  }
}  
</xmp>

<div class="note">
<b>Note:<b> Consider splitting out capabilities and ratings into seperate entries.
</div>

<div class="note">
<b>Note:<b> To be defined further.
</div>


## Behaviors ## {#behaviors}

### Haptics ### {#haptics}

Haptics is the use of vibration to provide feedback to the user as they interact with an image or object.

### Sonification ### {#sonification}

### High contrast ### {#high_contrast}

<div class="todo">
<b>TODO:</b> Reference and expand on CSS prefers-dark-mode media query.
</div>


### Voicing ### {#voicing}

### Tactiles ### {#tactiles}

#### Refreshable displays #### {#refreshable_displays}

#### Embossing #### {#embossing}



# Relationship to other technologies # {#tech_relationship}

## Scalable Vector Graphics (SVG) ## {#svg}

This specification is designed specifically with SVG in mind, though the metadata format can be used in other image types.

The SVG [[SVG11]] specification defines a metadata element (or "tag"), which can contain this metadata format. In the SVG 2.0 specification, defined in the late 1990s, it was expected that metadata would be expressed in XML; the SVG 2.0 specification lifts this restriction, and defines the metadata

It is important to note that currently, SVG does not define a processing algorithm or behavior for metadata. A user agent may process the metadata in any manner it supports. Currently, no general purpose web browser processes the contents of the metadata element.

Because the SVG metadata element does not have any defined attributes (such as an <code>href</code> attribute), there is no defined way to link to external resources; this contrasts with the style element in SVG, which can contain CSS rules as the child content of the element, or can reference external CSS files through the <code>href</code> attribute. Thus, this specification defines a linking syntax to allow external metadata files to be applied in whole or part to the referring image document.

## Cascading Style Sheets (CSS) ## {#css}

Some features of this specification, such as contrast control, overlap with capabilities of CSS, such as the prefers-high-contrast media query. This specification is designed to complement and extend such capabilities.

### CSS format ### {#css_format}

CSS defines its own syntax, processing model, and format, initially define in the 1990s. IT requires a custome processor.

This specification uses the common JSON format, which can be processed by any JSON tools, including web browser contexts, JavaScript, and many other tools.

This specification attempts to define its rules in a way that CSS might be expresssed in JSON.

### CSS selectors ### {#css_selectors}

This specification uses the CSS selector synta to link specific metadata entries to specific markup elements, to classes on markup elements, or other linking mechanisms. Unlike CSS, however, it does not use selectors as an "object key", but rather as a value for a selector attribute, to fit the JSON schema and allow multiple rules to use the same selector.

### Intended authoring usage ### {#intended_authoring}

To enable a CSS feature that is extended in this specification, the author can include the rule in either the metadata definition or the CSS definition.

If the rule is defined in the metadata, a user agent must apply in the same manner as if it were defined in the CSS. For a user agent that supports this specification, this can provide a greater degree of user control, ease authoring and maintenance, and decrease synchronization conflicts.

The author does not need to define it in both the metadata and the CSS, but might wish to do so for a user agent (such as a general-purpose web browser) that supports the feature in CSS but does not support this specification.

### Conflicts ### {#css_conflicts}

If a rule in a document's metadata conflicts with a hard-coded CSS rule, the CSS rule should take precedence, unless the user has made a preference selection, through a default settting or a specific selection at the time of viewing.

### Future adoption and integration into CSS ### {#future_css}

This specification defines some of its functionality in a way that could be integrated into future versions of CSS. Among other examples, the features that involve timing, such as haptics or sonification, are modeled after the animation syntax in CSS.



# Definitions # {#definitions}

## rule ## {#rule}

A rule is a combination of a selector and a behavior or data entry, which applies to an element or set of elements.

## media query ## {#media_query}

A conditional meta-rule that applies rules based on the capabilities and environment of a user agent or device. Defined by the W3C Media Queries Level 4 specification. Syntactically, they consist of an @ token operator followed by a string, followed by an optional condition set, where the string is one keyword from a pre-defined set of keywords denoting a capability or environmental variable, and the optional condition set is a value or range of values for that capability or environmental variable.

<div id='xmp_media_query_print' class='example'>
For example, the following media query expresses that a rule is used on printing devices only, with a resolution greater than 300 dots per CSS:

  <xmp highlight='css'>
  @media print and (min-resolution: 300dpi)
  </xmp>
</div>

## selector ## {#selector}

A pattern that matches against elements in a tree. Defined by the W3C CSS Selectors specification. Syntactically, they normally consist of a token followed by a string, where the token is the operator, and the string is an user-defined alphanumeric "word" assigned to an element in the markup.

The most common examples are the id selector (#), which matches the id of a single element (e.g. #bar-1, which matches the element with the id "bar-1"), and the class selector (.), which matches all instances of a string declared as the value of a class attribute (e.g. .bar, which matches all elements with the class including "bar").

## user ## {#user} 
## end user ## {#end_user}

The person experiencing or interacting with the image content, through whatever medium.

## user agent ## {#user_agent}

The software that processes and presents the document to the end user.
